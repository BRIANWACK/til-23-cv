{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jh/code/til/til-23-cv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "%cd .\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not on competition platform, exiting...\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "./setup.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Suspect Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from til_23_cv.reid import cli_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jh/.conda/envs/til/lib/python3.9/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9003', '--control=9001', '--hb=9000', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"74891908-2ad1-4dea-9897-2ac2e65327cc\"', '--shell=9002', '--transport=\"tcp\"', '--iopub=9004', '--f=/home/jh/.local/share/jupyter/runtime/kernel-v2-3897222ehmAkn1PJ6w.json'], args=['-c=cfg/reid.yaml'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# https://lightning.ai/docs/pytorch/stable/cli/lightning_cli_advanced_3.html#run-from-python\n",
    "cli = cli_main([\"-c=cfg/reid.yaml\"])\n",
    "trainer = cli.trainer\n",
    "model = cli.model\n",
    "data = cli.datamodule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `timm` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resmlp_12_224.fb_dino',\n",
       " 'resmlp_24_224.fb_dino',\n",
       " 'vit_base_patch8_224.dino',\n",
       " 'vit_base_patch14_dinov2.lvd142m',\n",
       " 'vit_base_patch16_224.dino',\n",
       " 'vit_giant_patch14_dinov2.lvd142m',\n",
       " 'vit_large_patch14_dinov2.lvd142m',\n",
       " 'vit_small_patch8_224.dino',\n",
       " 'vit_small_patch14_dinov2.lvd142m',\n",
       " 'vit_small_patch16_224.dino']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE:\n",
    "# {model}_{size}_{patch size}_{im size}.{train method}_{dataset}\n",
    "# m38m is Merged-38M, combines A LOT of datasets.\n",
    "# ft refers to fine-tuning on a smaller dataset later.\n",
    "# so m38m_ft_in22k_in1k means pretrained on Merged-38M, then finetuned on\n",
    "# ImageNet-22k followed by ImageNet-1k.\n",
    "# Clip models might be useful for their zero-shot capabilities.\n",
    "display(timm.list_models(pretrained=True, filter=\"*dino*\"))\n",
    "# backbone = \"eva02_large_patch14_448.mim_m38m_ft_in22k_in1k\"\n",
    "# backbone = \"eva02_tiny_patch14_336.mim_in22k_ft_in1k\"\n",
    "# https://huggingface.co/timm/vit_small_patch14_dinov2.lvd142m\n",
    "# backbone = \"vit_small_patch14_dinov2.lvd142m\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Augmentations\n",
    "\n",
    "See `notebooks/data.ipynb` for how to convert `til23plush` dataset to `til23reid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(data.nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "while False:\n",
    "    im = data.preview_transform(1)[0]\n",
    "    im = im.resize((1024, 1024))\n",
    "    im = np.array(im)[...,::-1]\n",
    "    cv2.imshow(\"example\", im)\n",
    "    key = chr(cv2.waitKey(0))\n",
    "    if key == \"q\":\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: Above saves checkpoints to `runs/lightning_logs/version_N/checkpoints`, pick the best for export!**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"runs/lightning_logs/version_4/checkpoints/epoch=11-val_sil_score=0.434.ckpt\"\n",
    "save_path = \"models/reid.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load checkpoint.\n",
    "ckpt = torch.load(ckpt_path)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jh/.conda/envs/til/lib/python3.9/site-packages/torch/__init__.py:1209: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n"
     ]
    }
   ],
   "source": [
    "# Trace & save model.\n",
    "encoder = model.model\n",
    "sz = model.hparams.im_size\n",
    "traced = torch.jit.trace(encoder, torch.rand(1, 3, sz, sz))\n",
    "torch.jit.save(traced, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# Check equality.\n",
    "traced = torch.jit.load(save_path)\n",
    "x = torch.rand(1, 3, sz, sz)\n",
    "print(torch.isclose(traced(x), model.model(x)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "til",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
