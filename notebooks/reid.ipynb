{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jh/code/til/til-23-cv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "%cd .\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not on competition platform, exiting...\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "./setup.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Suspect Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from til_23_cv.reid import cli_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jh/.conda/envs/til/lib/python3.9/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9003', '--control=9001', '--hb=9000', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"74891908-2ad1-4dea-9897-2ac2e65327cc\"', '--shell=9002', '--transport=\"tcp\"', '--iopub=9004', '--f=/home/jh/.local/share/jupyter/runtime/kernel-v2-3897222ehmAkn1PJ6w.json'], args=['-c=cfg/reid.yaml'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# https://lightning.ai/docs/pytorch/stable/cli/lightning_cli_advanced_3.html#run-from-python\n",
    "cli = cli_main(dict(config=\"cfg/reid.yaml\"))\n",
    "trainer = cli.trainer\n",
    "model = cli.model\n",
    "data = cli.datamodule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `timm` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resmlp_12_224.fb_dino',\n",
       " 'resmlp_24_224.fb_dino',\n",
       " 'vit_base_patch8_224.dino',\n",
       " 'vit_base_patch14_dinov2.lvd142m',\n",
       " 'vit_base_patch16_224.dino',\n",
       " 'vit_giant_patch14_dinov2.lvd142m',\n",
       " 'vit_large_patch14_dinov2.lvd142m',\n",
       " 'vit_small_patch8_224.dino',\n",
       " 'vit_small_patch14_dinov2.lvd142m',\n",
       " 'vit_small_patch16_224.dino']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE:\n",
    "# {model}_{size}_{patch size}_{im size}.{train method}_{dataset}\n",
    "# m38m is Merged-38M, combines A LOT of datasets.\n",
    "# ft refers to fine-tuning on a smaller dataset later.\n",
    "# so m38m_ft_in22k_in1k means pretrained on Merged-38M, then finetuned on\n",
    "# ImageNet-22k followed by ImageNet-1k.\n",
    "# Clip models might be useful for their zero-shot capabilities.\n",
    "display(timm.list_models(pretrained=True, filter=\"*dino*\"))\n",
    "# backbone = \"eva02_large_patch14_448.mim_m38m_ft_in22k_in1k\"\n",
    "# backbone = \"eva02_tiny_patch14_336.mim_in22k_ft_in1k\"\n",
    "# https://huggingface.co/timm/vit_small_patch14_dinov2.lvd142m\n",
    "# backbone = \"vit_small_patch14_dinov2.lvd142m\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Augmentations\n",
    "\n",
    "See `notebooks/data.ipynb` for how to convert `til23plush` dataset to `til23reid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(data.nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "while False:\n",
    "    im = data.preview_transform(1)[0]\n",
    "    im = im.resize((1024, 1024))\n",
    "    im = np.array(im)[...,::-1]\n",
    "    cv2.imshow(\"example\", im)\n",
    "    key = chr(cv2.waitKey(0))\n",
    "    if key == \"q\":\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: Above saves checkpoints to `runs/lightning_logs/version_N/checkpoints`, pick the best for export!**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Search\n",
    "\n",
    "This is only possible because the model converges and overfits quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need master branch for lightning 2.0 support.\n",
    "%pip install git+https://git@github.com/optuna/optuna.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "from til_23_cv.utils import OptunaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search objective.\n",
    "def objective(trial):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    arc_s = trial.suggest_float(\"arc_s\", 0.1, 15.0)\n",
    "    arc_m = trial.suggest_float(\"arc_m\", 0.15, 0.45)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-6, 5e-5, log=True)\n",
    "    # batch_size = trial.suggest_categorical(\"batch_size\", [64, 96, 128])\n",
    "\n",
    "    cli = cli_main(\n",
    "        dict(\n",
    "            config=\"cfg/reid.yaml\",\n",
    "            # Set sched_steps to -1 to disable OneCycle for better read on optimal LR.\n",
    "            model=dict(arc_s=arc_s, arc_m=arc_m, lr=lr, sched_steps=10000),\n",
    "            # data=dict(batch_size=batch_size),\n",
    "            trainer=dict(\n",
    "                callbacks=[OptunaCallback(trial=trial, monitor=\"val_sil_score\")],\n",
    "                default_root_dir=f\"runs/optuna/trial_{trial.number}\",\n",
    "                max_epochs=80,\n",
    "            ),\n",
    "        )\n",
    "    ) \n",
    "\n",
    "    print(\"Hyperparameters:\")\n",
    "    print(\n",
    "        \"arc_s:\", arc_s,\n",
    "        \"arc_m:\", arc_m,\n",
    "        \"lr:\", lr,\n",
    "        # \"batch_size:\", batch_size\n",
    "    )\n",
    "\n",
    "    trainer = cli.trainer\n",
    "    model = cli.model\n",
    "    data = cli.datamodule\n",
    "    trainer.fit(model, datamodule=data)\n",
    "\n",
    "    return model.best_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: runs/optuna/trial_74/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | VisionTransformer | 21.6 M\n",
      "1 | head  | ArcMarginProduct  | 76.8 K\n",
      "2 | loss  | CrossEntropyLoss  | 0     \n",
      "--------------------------------------------\n",
      "21.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.7 M    Total params\n",
      "86.822    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "arc_s: 12.076299801184774 arc_m: 0.28574758664587907 lr: 2.0280211776804368e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51d385af6774dec9b49bad40a672c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a53cd1d5a614f379a0cc9ff2ee956e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ef47c88ea840ac9e0d496c5a6efe8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a578fca1aa47b1b4189a96f9ec6283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ba450afc1246e7a0fd997f7df433fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57ddf08a50d4b819a4c3691d3c6e4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3442f99d5c10482eb37cfa0046b0661a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a983b748985d4fa680d693cee7816ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568636d1b37b45949e1f3e991dcc7db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346691a918b64f2faf0929248596f9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf25091884b4569a03d5f44acb53036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f93e7666a743a095ae5d64b3be63a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55f2025a5b341a69ee193e2795a9156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b1fe837b844481a78ea4d4990b9d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8da511640644dca87cdc7de65521c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc206a567254a26959630c1256a7061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f3abb91ac64372b02d6fb9e05b8fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543e4cd106cc44e9b968a54bfec764ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44ebb38dff5415890b3429ac449f9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcf4000cf1c498286582cad0fc3cc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c5032b2a114bd7adb2a22df2aad60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-05-31 09:47:52,848] Trial 74 finished with value: 0.4753156304359436 and parameters: {'arc_s': 12.076299801184774, 'arc_m': 0.28574758664587907, 'lr': 2.0280211776804368e-05}. Best is trial 64 with value: 0.5075626969337463.\n"
     ]
    }
   ],
   "source": [
    "# Search for hyperparameters.\n",
    "pruner = optuna.pruners.PatientPruner(\n",
    "    optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=8, n_warmup_steps=8, n_min_trials=2\n",
    "    ),\n",
    "    patience=8,\n",
    ")\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    study.optimize(objective, n_trials=500, timeout=int(60*60*12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 75\n",
      "Best trial:\n",
      "  ID: 64\n",
      "  Value: 0.5075626969337463\n",
      "  Params: \n",
      "    arc_s: 10.200518950277152\n",
      "    arc_m: 0.2956878768033506\n",
      "    lr: 1.735784634541476e-05\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of finished trials: {len(study.trials)}\")\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  ID: {trial.number}\".format())\n",
    "print(f\"  Value: {trial.value}\".format())\n",
    "print(f\"  Params: \")\n",
    "for k, v in trial.params.items():\n",
    "    print(f\"    {k}: {v}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"runs/lightning_logs/version_4/checkpoints/epoch=11-val_sil_score=0.434.ckpt\"\n",
    "save_path = \"models/reid.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load checkpoint.\n",
    "ckpt = torch.load(ckpt_path)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jh/.conda/envs/til/lib/python3.9/site-packages/torch/__init__.py:1209: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n"
     ]
    }
   ],
   "source": [
    "# Trace & save model.\n",
    "encoder = model.model\n",
    "sz = model.hparams.im_size\n",
    "traced = torch.jit.trace(encoder, torch.rand(1, 3, sz, sz))\n",
    "torch.jit.save(traced, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# Check equality.\n",
    "traced = torch.jit.load(save_path)\n",
    "x = torch.rand(1, 3, sz, sz)\n",
    "print(torch.isclose(traced(x), model.model(x)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "til",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
