{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jh/code/til/til-23-cv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "%cd .\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not on competition platform, exiting...\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "./setup.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Suspect Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from til_23_cv.reid import cli_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jh/.conda/envs/til/lib/python3.9/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9003', '--control=9001', '--hb=9000', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"74891908-2ad1-4dea-9897-2ac2e65327cc\"', '--shell=9002', '--transport=\"tcp\"', '--iopub=9004', '--f=/home/jh/.local/share/jupyter/runtime/kernel-v2-3897222ehmAkn1PJ6w.json'], args=['-c=cfg/reid.yaml'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# https://lightning.ai/docs/pytorch/stable/cli/lightning_cli_advanced_3.html#run-from-python\n",
    "cli = cli_main(config=\"cfg/reid.yaml\")\n",
    "trainer = cli.trainer\n",
    "model = cli.model\n",
    "data = cli.datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': None,\n",
       " 'seed_everything': 42,\n",
       " 'trainer': {'accelerator': 'auto',\n",
       "  'strategy': 'auto',\n",
       "  'devices': 'auto',\n",
       "  'num_nodes': 1,\n",
       "  'logger': None,\n",
       "  'callbacks': None,\n",
       "  'fast_dev_run': False,\n",
       "  'max_epochs': None,\n",
       "  'min_epochs': None,\n",
       "  'min_steps': None,\n",
       "  'max_time': None,\n",
       "  'limit_train_batches': None,\n",
       "  'limit_val_batches': None,\n",
       "  'limit_test_batches': None,\n",
       "  'limit_predict_batches': None,\n",
       "  'overfit_batches': 0.0,\n",
       "  'val_check_interval': None,\n",
       "  'check_val_every_n_epoch': 1,\n",
       "  'num_sanity_val_steps': None,\n",
       "  'log_every_n_steps': 1,\n",
       "  'enable_checkpointing': None,\n",
       "  'enable_progress_bar': None,\n",
       "  'enable_model_summary': None,\n",
       "  'accumulate_grad_batches': 1,\n",
       "  'gradient_clip_val': None,\n",
       "  'gradient_clip_algorithm': None,\n",
       "  'deterministic': False,\n",
       "  'benchmark': True,\n",
       "  'inference_mode': True,\n",
       "  'use_distributed_sampler': True,\n",
       "  'profiler': None,\n",
       "  'detect_anomaly': False,\n",
       "  'barebones': False,\n",
       "  'plugins': [<lightning.pytorch.plugins.precision.amp.MixedPrecisionPlugin at 0x7fe86030d4c0>],\n",
       "  'sync_batchnorm': False,\n",
       "  'reload_dataloaders_every_n_epochs': 0,\n",
       "  'default_root_dir': 'runs',\n",
       "  'max_steps': -1},\n",
       " 'model': {'model_name': 'vit_base_patch14_dinov2.lvd142m',\n",
       "  'pretrained': True,\n",
       "  'im_size': 224,\n",
       "  'arc_s': 10.200518950277152,\n",
       "  'arc_m': 0.2956878768033506,\n",
       "  'lr': 1.735784634541476e-05,\n",
       "  'sched_steps': -1},\n",
       " 'data': {'data_dir': 'data/til23reid',\n",
       "  'batch_size': 128,\n",
       "  'num_workers': 16,\n",
       "  'rgb_mean': (0.485, 0.456, 0.406),\n",
       "  'rgb_std': (0.229, 0.224, 0.225),\n",
       "  'im_size': 224}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cli.config.as_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `timm` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resmlp_12_224.fb_dino',\n",
       " 'resmlp_24_224.fb_dino',\n",
       " 'vit_base_patch8_224.dino',\n",
       " 'vit_base_patch14_dinov2.lvd142m',\n",
       " 'vit_base_patch16_224.dino',\n",
       " 'vit_giant_patch14_dinov2.lvd142m',\n",
       " 'vit_large_patch14_dinov2.lvd142m',\n",
       " 'vit_small_patch8_224.dino',\n",
       " 'vit_small_patch14_dinov2.lvd142m',\n",
       " 'vit_small_patch16_224.dino']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE:\n",
    "# {model}_{size}_{patch size}_{im size}.{train method}_{dataset}\n",
    "# m38m is Merged-38M, combines A LOT of datasets.\n",
    "# ft refers to fine-tuning on a smaller dataset later.\n",
    "# so m38m_ft_in22k_in1k means pretrained on Merged-38M, then finetuned on\n",
    "# ImageNet-22k followed by ImageNet-1k.\n",
    "# Clip models might be useful for their zero-shot capabilities.\n",
    "display(timm.list_models(pretrained=True, filter=\"*dino*\"))\n",
    "# backbone = \"eva02_large_patch14_448.mim_m38m_ft_in22k_in1k\"\n",
    "# backbone = \"eva02_tiny_patch14_336.mim_in22k_ft_in1k\"\n",
    "# https://huggingface.co/timm/vit_small_patch14_dinov2.lvd142m\n",
    "# backbone = \"vit_small_patch14_dinov2.lvd142m\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Augmentations\n",
    "\n",
    "See `notebooks/data.ipynb` for how to convert `til23plush` dataset to `til23reid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(data.nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "while False:\n",
    "    im = data.preview_transform(1)[0]\n",
    "    im = im.resize((1024, 1024))\n",
    "    im = np.array(im)[...,::-1]\n",
    "    cv2.imshow(\"example\", im)\n",
    "    key = chr(cv2.waitKey(0))\n",
    "    if key == \"q\":\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: Above saves checkpoints to `runs/lightning_logs/version_N/checkpoints`, pick the best for export!**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Search\n",
    "\n",
    "This is only possible because the model converges and overfits quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need master branch for lightning 2.0 support.\n",
    "%pip install git+https://git@github.com/optuna/optuna.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "from til_23_cv.utils import OptunaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 97 # 97 is batch size 128 for given dataset only.\n",
    "MAX_EPOCHS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search objective.\n",
    "def objective(trial):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    arc_s = trial.suggest_float(\"arc_s\", 0.1, 10.0)\n",
    "    arc_m = trial.suggest_float(\"arc_m\", 0.1, 0.8)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-6, 3e-5, log=True)\n",
    "    # batch_size = trial.suggest_categorical(\"batch_size\", [64, 96, 128])\n",
    "\n",
    "    cli = cli_main(\n",
    "        dict(\n",
    "            model=dict(\n",
    "                model_name=\"vit_base_patch14_dinov2.lvd142m\",\n",
    "                arc_s=arc_s,\n",
    "                arc_m=arc_m,\n",
    "                lr=lr,\n",
    "                # Set sched_steps to -1 to disable OneCycle for better read on optimal LR.\n",
    "                sched_steps=MAX_EPOCHS*STEPS_PER_EPOCH,\n",
    "            ),\n",
    "            # data=dict(batch_size=batch_size),\n",
    "            trainer=dict(\n",
    "                callbacks=[OptunaCallback(trial=trial, monitor=\"val_sil_score\")],\n",
    "                default_root_dir=f\"runs/optuna/trial_{trial.number}\",\n",
    "                max_epochs=MAX_EPOCHS,\n",
    "            ),\n",
    "        )\n",
    "    ) \n",
    "\n",
    "    print(\"Hyperparameters:\")\n",
    "    print(\n",
    "        \"arc_s:\", arc_s,\n",
    "        \"arc_m:\", arc_m,\n",
    "        \"lr:\", lr,\n",
    "        # \"batch_size:\", batch_size\n",
    "    )\n",
    "\n",
    "    trainer = cli.trainer\n",
    "    model = cli.model\n",
    "    data = cli.datamodule\n",
    "    trainer.fit(model, datamodule=data)\n",
    "\n",
    "    return model.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for hyperparameters.\n",
    "pruner = optuna.pruners.PatientPruner(\n",
    "    optuna.pruners.MedianPruner(\n",
    "        # 0.3 is default pct for OneCycle scheduler.\n",
    "        n_startup_trials=4, n_warmup_steps=int(MAX_EPOCHS*0.3), n_min_trials=2\n",
    "    ),\n",
    "    patience=4,\n",
    ")\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    study.optimize(objective, timeout=int(60*60*6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 75\n",
      "Best trial:\n",
      "  ID: 64\n",
      "  Value: 0.5075626969337463\n",
      "  Params: \n",
      "    arc_s: 10.200518950277152\n",
      "    arc_m: 0.2956878768033506\n",
      "    lr: 1.735784634541476e-05\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of finished trials: {len(study.trials)}\")\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  ID: {trial.number}\".format())\n",
    "print(f\"  Value: {trial.value}\".format())\n",
    "print(f\"  Params: \")\n",
    "for k, v in trial.params.items():\n",
    "    print(f\"    {k}: {v}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = trainer.checkpoint_callback.best_model_path\n",
    "ckpt_path = \"runs/lightning_logs/version_4/checkpoints/epoch=11-val_sil_score=0.434.ckpt\"\n",
    "save_path = \"models/reid.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"highest\")\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load checkpoint.\n",
    "ckpt = torch.load(ckpt_path)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jh/.conda/envs/til/lib/python3.9/site-packages/torch/__init__.py:1209: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n"
     ]
    }
   ],
   "source": [
    "# Trace & save model.\n",
    "encoder = model.model\n",
    "sz = model.hparams.im_size\n",
    "\n",
    "x = torch.rand(1, 3, sz, sz).cuda()\n",
    "encoder.cuda().eval()\n",
    "traced = torch.jit.trace(encoder, x)\n",
    "torch.jit.save(traced, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n",
      "tensor(7.9870e-06, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Check equality.\n",
    "with torch.inference_mode():\n",
    "    traced = torch.jit.load(save_path).eval()\n",
    "    x = torch.rand(1, 3, sz, sz).cuda()\n",
    "    print(torch.isclose(traced(x), encoder(x)).all())\n",
    "    print(abs(traced(x) - encoder(x)).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "til",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
