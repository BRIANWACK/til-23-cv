{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jh/code/til/til-23-cv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "%cd .\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not on competition platform, exiting...\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "./setup.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from til_23_cv import ReIDEncoder, cos_sim, thres_strategy_softmax, thres_strategy_naive\n",
    "from PIL import Image\n",
    "import tqdm as tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_path = \"models/det.pt\"\n",
    "reid_path = \"models/reid.pt\"\n",
    "\n",
    "yolo_cfg = dict(\n",
    "    conf=0.7,\n",
    "    iou=0.7,\n",
    "    half=True,\n",
    "    device=\"cuda:0\",\n",
    "    imgsz=1280,\n",
    "    stream=True,\n",
    "    # verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5m6u summary (fused): 323 layers, 41132004 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "detector = YOLO(yolo_path)\n",
    "detector.fuse()\n",
    "encoder = ReIDEncoder(reid_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"data/til23plush/images/test\"\n",
    "sus_dir = \"data/til23plush/suspects\"\n",
    "out_dir = \"runs/til23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview model output.\n",
    "def concat_images_horizontally(*images):\n",
    "    # Get the maximum height of the images\n",
    "    max_height = max(im.size[1] for im in images)\n",
    "\n",
    "    # Resize all images to the maximum height\n",
    "    resized_images = [im.resize((int(im.size[0] * max_height / im.size[1]), max_height)) for im in images]\n",
    "\n",
    "    # Concatenate the resized images horizontally\n",
    "    total_width = sum(im.size[0] for im in resized_images)\n",
    "    new_im = Image.new(\"RGB\", (total_width, max_height))\n",
    "    x_offset = 0\n",
    "    for im in resized_images:\n",
    "        new_im.paste(im, (x_offset, 0))\n",
    "        x_offset += im.size[0]\n",
    "\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding strategies.\n",
    "naive_thres = lambda x: thres_strategy_naive(x, 0.3) \n",
    "softmax_thres = lambda x: thres_strategy_softmax(x, 0.8, 1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1600/1600 /home/jh/code/til/data/til23plush/images/test/image_1599.png: 768x1280 3 plushies, 58.2ms\n",
      "Speed: 3.0ms preprocess, 66.4ms inference, 3.5ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    }
   ],
   "source": [
    "# Save results!\n",
    "from IPython.display import clear_output\n",
    "from time import sleep, time\n",
    "\n",
    "sus_dir = Path(sus_dir)\n",
    "out_dir = Path(out_dir)\n",
    "if out_dir.exists():\n",
    "    out_dir.rename(out_dir.with_name(f\"{out_dir.name}_{int(time())}\"))\n",
    "(out_dir / \"yolo\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "with open(out_dir / \"results.csv\", \"w\") as f:\n",
    "    fields = [\"Image_ID\", \"class\", \"confidence\", \"ymin\", \"xmin\", \"ymax\", \"xmax\"]\n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for res in detector.predict(test_dir, **yolo_cfg):\n",
    "        res = res.cpu()\n",
    "        im = res.orig_img\n",
    "        res_pth = Path(res.path)\n",
    "        \n",
    "        sus = np.array(Image.open(sus_dir / res_pth.name))\n",
    "        sus_embed = encoder([sus])[0]\n",
    "\n",
    "        boxes = res.boxes.xyxy.round().int()\n",
    "        crops = []\n",
    "        for x1, y1, x2, y2 in boxes:\n",
    "            x1 = max(0, x1)\n",
    "            y1 = max(0, y1)\n",
    "            x2 = min(im.shape[1], x2)\n",
    "            y2 = min(im.shape[0], y2)\n",
    "            crops.append(im[y1:y2, x1:x2, ::-1])\n",
    "\n",
    "        box_embeds = encoder(crops)\n",
    "        box_sims = [cos_sim(e, sus_embed) for e in box_embeds]\n",
    "        idx = naive_thres(box_sims)\n",
    "\n",
    "        # res.boxes.conf[:] = torch.tensor(box_sims) # np.clip(box_sims, 0, 1)\n",
    "        if idx != -1:\n",
    "            res.boxes.cls[idx] = 1\n",
    "\n",
    "        # Save YOLO predictions for eyeballing.\n",
    "        res.save_txt(out_dir / \"yolo\" / f\"{res_pth.stem}.txt\", save_conf=True)\n",
    "        # Save CSV for submission.\n",
    "        for i in range(len(res.boxes)):\n",
    "            writer.writerow({\n",
    "                \"Image_ID\": res_pth.stem,\n",
    "                \"class\": int(res.boxes.cls[i]),\n",
    "                \"confidence\": float(res.boxes.conf[i]),\n",
    "                \"ymin\": float(res.boxes.xyxyn[i][1]),\n",
    "                \"xmin\": float(res.boxes.xyxyn[i][0]),\n",
    "                \"ymax\": float(res.boxes.xyxyn[i][3]),\n",
    "                \"xmax\": float(res.boxes.xyxyn[i][2]),\n",
    "            })\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        # Preview.\n",
    "        if False: \n",
    "            print(box_sims, idx + 1 if idx != -1 else \"None\")\n",
    "            display(concat_images_horizontally(*[Image.fromarray(c) for c in crops], Image.fromarray(sus)))\n",
    "            sleep(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: Results are saved to `runs/til23/results.csv`!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "til",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
